# IMAGE (VIDEO) TO LINEART COMFYUI WORKFLOW

This docker was made using as reference [this one.](https://github.com/ValyrianTech/ComfyUI_with_Flux)

From [MANA PRODUCTIONS](https://linktr.ee/manaproductions), this runpod is designed to have a straightway setup to process hundred of frames with a powerful GPU in Runpod to improve efficiency on the rotoscope process. **WARNING: NOT ALL FRAMES MAY BE CONSISTENT, 99% OF THE RESULTS ARE RIGHT**

[Watch how the results are by clicking here!](https://www.youtube.com/watch?v=XoBNEtDwHKc)

## Software

* **8888** *Jupyter Lab*
* **8188** *ComfyUI*
* **4040** *FileBrowser*

## Model used

This is using the **GGUF Q6_K** variant of **Qwen Image Edit** so this can run on 12GB VRAM GPUs (no need for the expensive options) and also is the one we use locally so we are confident about the results.

## Preparing

Use ffmpeg to extract the frames from a video. Here a simple command:

`ffmpeg -r 1 -i video.mp4 -r 1 "%03d.jpg"`

And upload these frames with *FileBrowser* in `/workspace/`

If you have a mask for these frames (generated by [MatAnyone](https://github.com/deepbeepmeep/Wan2GP) for example), you have to put them in a folder with the same folder name but adding the suffix "_alpha".

Example:

`scene1`

`scene1_alpha`

If you don't want to use alpha frames, **you can disable them** in the workflow.






